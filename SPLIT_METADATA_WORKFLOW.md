# Split Metadata Workflow Diagram

## ðŸ”„ Complete Split Metadata Workflow

```mermaid
graph TD
    A[ðŸ“ Original Dataset] --> B[ðŸ” DVC Version Control]
    B --> C[ðŸ“Š Generate Dataset Hash]
    C --> D[ðŸ”„ Create Data Splits]
    D --> E[ðŸ“‹ Generate Split Metadata]
    E --> F[ðŸ’¾ Store Split Files]
    F --> G[ðŸ”‘ Version Each Split]
    G --> H[ðŸ“„ Save Split Metadata]
    
    H --> I[âœ… Reproducible Experiments]
    H --> J[ðŸ”¬ Model Training]
    H --> K[ðŸ“Š Validation & Testing]
    H --> L[ðŸš€ Model Deployment]
```

## ðŸ“Š Split Metadata Structure

```json
{
  "split_name": "emotion_classification",
  "original_dataset": "demo_data/initial_dataset.csv",
  "train_ratio": 0.7,
  "val_ratio": 0.15,
  "test_ratio": 0.15,
  "random_seed": 42,
  "train_hash": "fd1224a1ccc43d617626288c08cf1196c54569e929998d8cc10f2d824d2f05b8",
  "val_hash": "39afb051edb5e51a909a700533e1ada115a64468cadfb2e8e62134c313c64caf",
  "test_hash": "c73a304d98b462ec5da1c1fbdfcdb7bd24e8e076ee8b11e930c5a77035e4758d",
  "created_at": "2025-08-01T15:23:54.267897"
}
```

## ðŸ” Split Metadata Creation Process

```mermaid
sequenceDiagram
    participant U as User
    participant DVC as DataVersionControl
    participant FS as File System
    participant SM as Split Metadata
    
    U->>DVC: create_data_split(dataset_path, split_name, ratios, seed)
    DVC->>FS: Load original dataset
    FS-->>DVC: Dataset content
    DVC->>DVC: Set random seed (42)
    DVC->>DVC: Create reproducible splits
    DVC->>FS: Save train.csv, val.csv, test.csv
    DVC->>DVC: Version each split file
    DVC->>SM: Create split metadata
    SM-->>DVC: Metadata with hashes
    DVC->>FS: Save split_metadata.json
    DVC-->>U: Return split paths and metadata
```

## ðŸ—ï¸ Project Structure with Split Metadata

```
Speaking Feedback Tool/
â”œâ”€â”€ ðŸ“ data/
â”‚   â”œâ”€â”€ ðŸ“„ data_versions.json              # Main DVC Registry
â”‚   â”œâ”€â”€ ðŸ“ raw/
â”‚   â”‚   â””â”€â”€ ðŸ“„ emotion_dataset.csv         # Original Dataset
â”‚   â””â”€â”€ ðŸ“ splits/
â”‚       â”œâ”€â”€ ðŸ“ emotion_classification/
â”‚       â”‚   â”œâ”€â”€ ðŸ“„ train.csv              # Training Split
â”‚       â”‚   â”œâ”€â”€ ðŸ“„ val.csv                # Validation Split
â”‚       â”‚   â”œâ”€â”€ ðŸ“„ test.csv               # Test Split
â”‚       â”‚   â””â”€â”€ ðŸ“„ split_metadata.json    # Split Metadata
â”‚       â””â”€â”€ ðŸ“ validation_testing/
â”‚           â”œâ”€â”€ ðŸ“„ train.csv              # Another Split
â”‚           â”œâ”€â”€ ðŸ“„ val.csv
â”‚           â”œâ”€â”€ ðŸ“„ test.csv
â”‚           â””â”€â”€ ðŸ“„ split_metadata.json    # Another Split Metadata
â”œâ”€â”€ ðŸ“ models/
â”‚   â””â”€â”€ ðŸ“ custom/
â”‚       â”œâ”€â”€ ðŸ“„ random_forest_emotion_model.pkl
â”‚       â”œâ”€â”€ ðŸ“„ logistic_regression_emotion_model.pkl
â”‚       â””â”€â”€ ðŸ“„ gradient_boosting_emotion_model.pkl
â””â”€â”€ ðŸ“ pipeline_results/
    â””â”€â”€ ðŸ“„ pipeline_results_*.json
```

## ðŸŽ¯ Purpose of Split Metadata

### 1. **Reproducibility**
```
ðŸ”‘ Same Input + Same Seed = Same Splits
â”œâ”€â”€ Original dataset hash
â”œâ”€â”€ Split ratios (70/15/15)
â”œâ”€â”€ Random seed (42)
â””â”€â”€ Individual split hashes
```

### 2. **Data Lineage Tracking**
```
ðŸ“Š Complete Data Lineage
â”œâ”€â”€ Original dataset â†’ Split metadata
â”œâ”€â”€ Split metadata â†’ Individual splits
â”œâ”€â”€ Individual splits â†’ Model training
â””â”€â”€ Model training â†’ Model deployment
```

### 3. **Experiment Reproducibility**
```
ðŸ”¬ Reproducible Experiments
â”œâ”€â”€ Load split metadata
â”œâ”€â”€ Verify split integrity
â”œâ”€â”€ Use exact same splits
â””â”€â”€ Reproduce model results
```

### 4. **Team Collaboration**
```
ðŸ‘¥ Team Collaboration
â”œâ”€â”€ Share original dataset + split metadata
â”œâ”€â”€ Each member recreates identical splits
â”œâ”€â”€ All use same train/val/test sets
â””â”€â”€ Consistent model evaluation
```

## ðŸ”„ Split Metadata Workflow States

```mermaid
stateDiagram-v2
    [*] --> OriginalDataset: Create dataset
    OriginalDataset --> VersionedDataset: dvc.version_dataset()
    VersionedDataset --> SplitCreation: dvc.create_data_split()
    SplitCreation --> SplitMetadata: Generate metadata
    SplitMetadata --> VersionedSplits: Version each split
    VersionedSplits --> ModelTraining: Use in training
    ModelTraining --> ModelDeployed: Deploy model
    ModelDeployed --> [*]
    
    SplitMetadata --> ExperimentReproduction: Reproduce experiment
    ExperimentReproduction --> ModelTraining
```

## ðŸ” Split Integrity Verification

```mermaid
flowchart TD
    A[ðŸ“„ Split Metadata] --> B[ðŸ”‘ Load Expected Hashes]
    B --> C[ðŸ“ Locate Split Files]
    C --> D[ðŸ” Calculate Current Hashes]
    D --> E{Hash Match?}
    E -->|Yes| F[âœ… Splits Verified]
    E -->|No| G[âŒ Split Corruption]
    F --> H[ðŸ¤– Proceed with Training]
    G --> I[ðŸ›‘ Stop Process]
```

## ðŸ“Š Split Metadata Benefits

### âœ… **Reproducibility**
- **Deterministic splits**: Same seed = same splits
- **No data leakage**: Proper train/val/test separation
- **Experiment reproduction**: Exact same data splits

### âœ… **Data Lineage**
- **Complete tracking**: From original to splits to models
- **Audit trail**: Track which splits were used
- **Version control**: Each split is versioned

### âœ… **Team Collaboration**
- **Shared splits**: All team members use identical splits
- **Consistent evaluation**: Same validation/test sets
- **Easy sharing**: Share metadata + original dataset

### âœ… **MLOps Best Practices**
- **Model versioning**: Link models to specific splits
- **Experiment tracking**: Store split metadata with experiments
- **Deployment safety**: Verify split integrity before deployment

## ðŸš€ Real-World Usage Scenarios

### Scenario 1: Creating Reproducible Splits
```
1. ðŸ“ Load original dataset
2. ðŸ” Version the original dataset
3. ðŸ”„ Create splits with specific ratios
4. ðŸ“‹ Generate split metadata
5. ðŸ’¾ Save all split files and metadata
6. ðŸ”‘ Version each split individually
```

### Scenario 2: Reproducing Experiments
```
1. ðŸ“„ Load split metadata from experiment
2. ðŸ”‘ Extract expected split hashes
3. ðŸ” Verify split file integrity
4. âœ… Use verified splits for training
5. ðŸ¤– Train model with exact same data
6. ðŸ“Š Reproduce model results
```

### Scenario 3: Team Collaboration
```
1. ðŸ“¤ Share original dataset with team
2. ðŸ“„ Share split metadata with team
3. ðŸ”„ Each member recreates splits
4. ðŸ” Verify split integrity
5. âœ… All use identical train/val/test sets
6. ðŸ¤– Train models with same data
```

### Scenario 4: Model Deployment
```
1. ðŸ“‹ Store split metadata with model
2. ðŸ” Verify split integrity before deployment
3. ðŸš€ Deploy model with verified data
4. ðŸ“Š Track which splits were used
```

## ðŸ”‘ Core Split Metadata Functions

```python
# Create reproducible splits
def create_data_split(dataset_path, split_name, train_ratio=0.7, 
                     val_ratio=0.15, test_ratio=0.15, random_seed=42):
    """
    Creates reproducible data splits with metadata
    """
    # 1. Load original dataset
    # 2. Set random seed for reproducibility
    # 3. Create splits with specified ratios
    # 4. Save split files
    # 5. Version each split
    # 6. Generate split metadata
    # 7. Save metadata file
    # 8. Return split paths and metadata

# Verify split integrity
def verify_split_integrity(split_metadata_path):
    """
    Verifies that split files match metadata hashes
    """
    # 1. Load split metadata
    # 2. Extract expected hashes
    # 3. Calculate current hashes
    # 4. Compare hashes
    # 5. Return verification result

# Reproduce splits
def reproduce_splits(original_dataset_path, split_metadata):
    """
    Reproduces splits from original dataset using metadata
    """
    # 1. Load original dataset
    # 2. Extract split parameters from metadata
    # 3. Set random seed from metadata
    # 4. Create splits with same ratios
    # 5. Verify against metadata hashes
    # 6. Return reproduced splits
```

## ðŸ“ˆ Integration with MLOps Pipeline

```mermaid
graph TD
    A[ðŸ“Š Original Dataset] --> B[ðŸ” DVC Versioning]
    B --> C[ðŸ”„ Create Splits]
    C --> D[ðŸ“‹ Split Metadata]
    D --> E[ðŸ¤– Model Training]
    E --> F[ðŸ“Š Model Evaluation]
    F --> G[ðŸ“‹ Model Registry]
    G --> H[ðŸš€ Model Deployment]
    H --> I[ðŸ“Š Monitoring]
    I --> J[ðŸ”„ Data Drift Detection]
    J --> K[ðŸ“ˆ Retraining Trigger]
    K --> A
```

## ðŸŽ¯ Key Split Metadata Concepts

### 1. **Reproducible Splits**
```
Input: emotion_dataset.csv (1,000 samples)
Parameters: train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, seed=42
Output: 
â”œâ”€â”€ train.csv (700 samples)
â”œâ”€â”€ val.csv (150 samples)
â”œâ”€â”€ test.csv (150 samples)
â””â”€â”€ split_metadata.json
```

### 2. **Split Metadata Structure**
```json
{
  "split_name": "emotion_classification",
  "original_dataset": "demo_data/initial_dataset.csv",
  "train_ratio": 0.7,
  "val_ratio": 0.15,
  "test_ratio": 0.15,
  "random_seed": 42,
  "train_hash": "fd1224a1ccc43d61...",
  "val_hash": "39afb051edb5e51a...",
  "test_hash": "c73a304d98b462ec...",
  "created_at": "2025-08-01T15:23:54.267897"
}
```

### 3. **Data Lineage Chain**
```
Original Dataset â†’ Split Metadata â†’ Individual Splits â†’ Model Training â†’ Model Deployment
```

## ðŸš€ Next Steps

1. **ðŸ“Š Real Data Integration**: Use actual datasets instead of dummy data
2. **ðŸ”— CI/CD Integration**: Automate split verification in pipelines
3. **ðŸ“ˆ Advanced Monitoring**: Set up alerts for split drift
4. **ðŸ‘¥ Team Workflows**: Implement proper split sharing protocols
5. **ðŸ”’ Security**: Add encryption for sensitive split data

---

*This diagram shows how split metadata ensures reproducible data splits and integrates with the overall DVC system for robust MLOps workflows.* 